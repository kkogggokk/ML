{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. SVM(Support Vector Machine)\n",
    "## 8.1 Linear SVM \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마진 실습\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y = True) \n",
    "\n",
    "# split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, stratify= y, random_state=1)\n",
    "\n",
    "# preprocessing \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# model : SVC \n",
    "svc = SVC(kernel = 'linear', # svc = LinearSVC() \n",
    "          C = 1, # hyper param :  0.1, 0.01 <-- 1(default) --> 10, 100\n",
    "          random_state = 1)\n",
    "svc.fit(X_train_scaled, y_train)\n",
    "\n",
    "# predict \n",
    "pred_train = svc.predict(X_train_scaled)\n",
    "pred_test = svc.predict(X_test_scaled)\n",
    "\n",
    "# accuracy : svc의 C값에 따라 값이 달라진다. 1을 기준으로 변경해보자. \n",
    "print('- svc train accuracy :', accuracy_score(y_train,pred_train))\n",
    "print('- svc test  accuracy :', accuracy_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@ 질문 \n",
    "- 수업을 안들어서 그런데 return_X_y  뭘 의미?\n",
    "- 전처리 시 판단법 \n",
    "- 어떤 지점에 random_state를 넣어줘야하는가?\n",
    "- SVM, SVC ? \n",
    "- svc = LinearSVC()  으로 처리해줘도 C값 하이퍼파라미터 줄수 있나?\n",
    "- C 값이 의미하는게 정확히 뭐야? 오차의 허용범위? \n",
    "- 최적의 C값을 찾아주는건 없어? 그리드서치 \n",
    "\n",
    "\n",
    "[결론]\n",
    "- C 값이 커질수록 train값은 좋아지나 test 값이 줄어들면서 일반화가 어려워진다. ==> overfitting \n",
    "- C 값이 작을수록 train, test 둘다 성능이 안 좋아진다. ==> underfitting \n",
    "\n",
    "\n",
    "- 그렇다면 비선형데이터일때는 어떻게? --> 커널서포트 벡터 머신 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 비선형데이터일때 \n",
    "### 8.2.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 비선형 데이터일때는?\n",
    "- Kernel Support Vercotr machine \n",
    "- Kernel Trick \n",
    "- RBF \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBF 예제 - recall_score, precision_score \n",
    "from sklearn.metrics import recall_score, precision_score \n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "# split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, stratify= y, random_state=1)\n",
    "\n",
    "# preprocessing \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# model : rbf\n",
    "rbf_svc = SVC(kernel = 'rbf',  # default : rbf\n",
    "              C = 1, # soft margin -- 1 -- hard margin \n",
    "              gamma = 0.1, # underfitting -- 일반화 -- overfitting\n",
    "              probability=True, # predict_proba(), roc_auc_score, average_precision_score를 쓰기 위해서 설정 (default:Flase)\n",
    "              random_state=1\n",
    ")\n",
    "rbf_svc.fit(X_train_scaled, y_train)\n",
    "\n",
    "# predict \n",
    "pred_train = rbf_svc.predict(X_train_scaled)\n",
    "pred_test = rbf_svc.predict(X_test_scaled)\n",
    "\n",
    "# C : 1, gammar : 1 -> 0.5 -> 0.1 -> 0.01 , C값을 고정해 놓고 감마 값을 조정해보자. \n",
    "print('- rbf_train accuracy :',accuracy_score(y_train, pred_train))\n",
    "print('- rbf_test  accuracy :',accuracy_score(y_test, pred_test))\n",
    "\n",
    "print('- rbf_train recall :',recall_score(y_train, pred_train))\n",
    "print('- rbf_test  recall :',recall_score(y_test, pred_test))\n",
    "\n",
    "# RBF 예제 - roc_auc_score, average_precision_score\n",
    "# 양성의 확률 error : why? predict_proba is not available when  probability=False\n",
    "# svm모델은 기본적으로 False로 설정되어 있기 때문에 확률값을 확인하기 위해서는 True로 설정해줘야 한다. \n",
    "pos_proba = rbf_svc.predict_proba(X_train_scaled)[:,1] \n",
    "print('- rbf_train roc_auc_score :',roc_auc_score(y_train, pos_proba))\n",
    "print('- rbf_train average_precision_score :',average_precision_score(y_train, pos_proba))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@ 질문\n",
    "- scaled를 넣어줘야할때느 언제 ? \n",
    "- proba를 왜 썼었지? roc_auc_score, average_precision_score를 쓰기위함 맞나?\n",
    "- 근데 값을 보고 딱 오버피팅이다 언더피팅이다 감이 잘 안오는거 같아.. \n",
    "- 적절할 C와 감마 값을 구하기 위해서 필요한 것 ==> GridSearch 를 통해서 최적의 조합을 찾는다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 최적의 조합을 찾아라 GridSearch\n",
    "# GridSearch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearch 예제 \n",
    "\n",
    "param = {\n",
    "    'kernel' : ['rbf','linear'],\n",
    "    'C' : [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'gamma' : [0.001, 0.01, 0.1, 1, 10] # rbf를 위해 넣어준다. linear일때 의미없는 값 \n",
    "}\n",
    "svc = SVC(random_state=1, probability= True) # roc_auc 위해 설정\n",
    "gs_svc = GridSearchCV(svc,\n",
    "                      param_grid = param,\n",
    "#                       scoring='accuracy',\n",
    "                      scoring=['accuracy','roc_auc'], # roc_auc위해 probability 설정 \n",
    "                      cv = 3, \n",
    "                      n_jobs = -1 \n",
    ")\n",
    "gs_svc.fit(X_train_scaled, y_train)\n",
    "\n",
    "print('- best_params_ : ', gs_svc.best_params_)\n",
    "\n",
    "# 데이터프레임 표로 확인 \n",
    "pd.DataFrame(gs_svc.cv_results_)#.sort_values('rank_test_score').head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the parameter refit ? \n",
    "\n",
    "ValueError: For multi-metric scoring, the parameter refit must be set to a scorer key or a callable to refit an estimator with the best parameter setting on the whole data and make the best_* attributes available for that metric. If this is not needed, refit should be set to False explicitly. True was passed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그리드 서치자체에서 크로스밸리데이션도 하기 때문에 크로스밸리데이션 하지 않아도 된다는 이야기인가? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_val_score() \n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "svc2 = SVC(C = 10, gamma = 0.01)\n",
    "\n",
    "result = cross_val_score(svc2,\n",
    "                         X_train_scaled,\n",
    "                         y_train,\n",
    "                         scoring='accuracy',\n",
    "                         cv = 3\n",
    ")\n",
    "print('- result :',result)\n",
    "print('- mean   :',np.mean(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 예제  todo \n",
    "## iris DataSet으로 분류 --> 다시 확인 \n",
    "- 다중 클래스 분류\n",
    "- model : GridSearch\n",
    "- 평가지표 : accuracy \n",
    "- 파이프라인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "X, y = load_iris(return_X_y = True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--\n",
    "# References      \n",
    "> - 김성환, 엔코아 플레이데이터 (2021, 인공지능 개발자 3기 과정)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
