{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 인공지능개요\n",
    "## 1.1 인공지능이란\n",
    "- 다트머스대학 수학과 교수인 존 매카시(John McCarthy)가 \"지능이 있는 기계를 만들기 위한 과학과 공학\" 이란 논문에서 처음으로 제안(1955년)\n",
    "- 인간의 지능(인지, 추론, 학습 등)을 컴퓨터나 시스템 등으로 만든 것 또는, 만들 수 있는 방법론이나 실현 가능성 등을 연구하는 기술 또는 과학\n",
    "\n",
    "## 1.2 튜링테스트\n",
    "\n",
    "\n",
    "## 1.3 중국어방의 역설\n",
    "\n",
    "## 1.4 StringAI, WeekAI\n",
    "- 인간이 할 수 있는 모든 지적인 업무를 해낼 수 있는 (가상적인) 기계의 지능을 말한다. 인공지능 연구의 주요 목표\n",
    "\n",
    "|Strong AI (강 인공지능)|Week AI (약 인공지능)|\n",
    "|--|--|\n",
    "|- AGI 성능을 가지는 인공지능|    - 기존에 인간은 쉽게 해결할 수 있었지만 컴퓨터로 처리하기 어려웠던 일을 컴퓨터가 수행할 수 있도록 하는 것이 목적|\n",
    "|- 인공지능 연구가 목표하는 방향.|.- 지각(知覺)을 가지고 있지 않으며 특정한 업무를 처리하는데 집중한다.\n",
    "\n",
    "\n",
    "## 1.5 발전 가능했던 3가지 요소\n",
    "1. 데이터의 급격한 증가\n",
    "    - 디지털사진, 동영상, IoT 기기, SNS 컨텐츠 등으로 인해 데이터가 폭발적으로 증가 \n",
    "    - 전 세계 디지털데이터의 90%가 최근 2년 동안 생성 \n",
    "1. 알고리즘의 발전\n",
    "    - 급증한 데이터를 이용한 기존 알고리즘 개선 및 새로운 알고리즘들이 개발됨.\n",
    "1. 컴퓨터 하드웨어의 발전\n",
    "    - CPU와 GPU의 발전. \n",
    "    - 특히 GPU의 발전은 딥러닝의 발전으로 이어짐.\n",
    "    - TPU(Tensor Processing Unit): 구글에서 개발한 딥러닝 전용 칩셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 머신러닝과 딥러닝 \n",
    "\n",
    "|머신러닝|딥러닝|\n",
    "|--|--|\n",
    "|- 데이터 학습 기반의 인공 지능 분야<br>- 기계에게 어떻게 동작할지 일일이 코드로 명시하지 않고 데이터를 이용해 학습할 수 있도록 하는 알고리즘과 기술을 개발하는 인공지능의 한분야|- 인공신경망 알고리즘을 기반으로 하는 머신러닝의 한 분야. <br>- 대용량 데이터 학습에 뛰어난 성능을 나타낸다.|\n",
    "\n",
    "## 2.1 모델(알고리즘, 모형)\n",
    "- 모델이란 데이터의 패턴을 수식화 한 함수를 말한다.\n",
    "- 그러나 처음에는 방대한 데이터의 패턴을 알 수 없기 때문에 \"이 데이터는 이런 패턴을 가졌을 것\"이라고 가정한 함수를 정한뒤 데이터를 학습시켜 데이터 패턴을 잘 표현하는 함수를 만든다.\n",
    "- 모델을 만드는 과정 \n",
    "    1. 모델을 정하여 수식화 한다. \n",
    "    2. 모델을 데이터를 이용해 학습(Train)시킨다. 모델을 데이터의 패턴에 맞춘다.(fit)\n",
    "    3. 학습된 모델이 얼마나 데이터 패턴을 잘 표현하는지 평가한다.(Test)\n",
    "\n",
    "## 2.3 feature, label\n",
    "1. feature\n",
    "    - 예측 하거나 분류해야 하는 데이터의 **특성, 속성 값**\n",
    "    - **입력 변수(Input), 독립변수**라고도 한다.\n",
    "    - 일반적으로 **X**로 표현한다.\n",
    "2. label\n",
    "    - 예측하거나 분류해야 하는 값\n",
    "    - **출력 변수(Output), 종속변수**라고도 한다.\n",
    "    - 일반적으로 **y**로 표현한다.\n",
    "\n",
    "![](data:image/png;base64,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)\n",
    "\n",
    "## 2.5 머신러닝 개발절차 \n",
    "|절차|과정|내용|\n",
    "|--|--|--|\n",
    "|1|Business Understanding|머신러닝 개발을 통해 얻고자 하는 것 파악|\n",
    "|2|Data Understanding|데이터 수집, 탐색을 통해 데이터 파악|\n",
    "|3|Data Preparation|데이터 전처리|\n",
    "|4|Modeling|머신러닝 모델 선정, 모델 학습|\n",
    "|5|Evaluation|모델 평가, 평가 결과에 따라 위 프로세스 반복\n",
    "|6|Deployment|평가 결과가 좋으면 실제 업무에 적용|\n",
    "\n",
    "![](http://www.kdnuggets.com/wp-content/uploads/crisp-dm-4-problems-fig1.png)\n",
    "\n",
    "## 2.6 파이썬 머신러닝,딥러닝 패키지\n",
    "\n",
    "|패키지|내용|\n",
    "|--|--|\n",
    "|Scikit-learn|- 딥러닝을 제외한 머신러닝 주요 알고리즘 제공|\n",
    "|Tensorflow|- 구글 브레인 팀이 개발한 텐서플로우는 머신러닝 및 딥러닝 위한 오픈소스 라이브러리다.|\n",
    "|Keras|- 딥러닝 모델을 쉽게 만들 수 있도록 다양한 딥러닝 플랫폼 위에서 실행되는 고수준 딥러닝 패키지.<br>- Tensorflow 2.0 부터 keras를 포함하고 있다.|\n",
    "|pytorch|- 토치(Torch) 및 카페2(Caffe2) 프레임워크를 기반으로한 페이스북에서 만든 딥러닝 프레임워크|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 머신러닝 알고리즘 분류 \n",
    "## 3.1 지도학습(Supervised Learning)\n",
    "- 모델에게 데이터의 **특징(Feature)와 정답(Label)**을 알려주며 학습시킨다.\n",
    "- 대부분의 머신러닝은 지도학습이다.\n",
    "\n",
    "\n",
    "### 3.1.1 분류(Classification)\n",
    "- 두개 이상의 클래스(범주)에서 선택을 묻는 지도 학습방법\n",
    "    - 이진 분류 : 분류 대상 클래스가 2개\n",
    "    - 다중 분류 : 분류 대상 클래스가 여러개\n",
    "- 의사결정트리(Decision Tree)\n",
    "- 로지스틱 회귀(Logistic Regression)\n",
    "- K-최근접 이웃(K-Nearest Neighbors, KNN)\n",
    "- 나이브 베이즈(Naive Bayes)\n",
    "- 서포트 벡터 머신(Support Vector Machine, SVM)\n",
    "- 랜덤 포레스트(Random Forest)\n",
    "- 신경망(Neural Network)\n",
    "   \n",
    "   \n",
    "### 3.1.2 회귀(Regression)\n",
    "- 숫자(연속된값)를 예측 하는 지도학습\n",
    "- 의사결정트리(Decision Tree)\n",
    "- 선형 회귀(Linear Regression)\n",
    "- 릿지 회귀(Rige Regression)\n",
    "- 라쏘 회귀(Lasso Regression)\n",
    "- 엘라스틱 넷(Elastic Net)\n",
    "- K-최근접 이웃(K-Nearest Neighbors, KNN)\n",
    "- 나이브 베이즈(Naive Bayes)\n",
    "- 서포트 벡터 머신(Support Vector Machine, SVM)\n",
    "- 랜덤 포레스트(Random Forest)\n",
    "- 신경망(Neural Network)\n",
    "\n",
    "## 3.2 비지도학습 (Unsupervised Learning)\n",
    "- **정답이 없이** 데이터의 특징만 학습하여 데이터간의 **관계**를 찾는 학습방법\n",
    "\n",
    "\n",
    "### 3.2.1 군집(Clustering)\n",
    "- 비슷한 유형의 데이터 그룹을 찾는다. 주로 데이터 경향성을 파악하는 비지도 학습\n",
    "- K-평균 클러스터링(K-Means Clustering)\n",
    "- 평균점 이동 클러스터링(Mean-Shift Clustering) \n",
    "- DBSCAN(DensityBased Spatial Clustering of Applications with Noise)\n",
    "\n",
    "\n",
    "### 3.2.2 차원축소(Dimensionality Reduction)\n",
    "- 예측에 영향을 최대한 주지 않으면서 변수(Feature)를 축소하는 한다.\n",
    "- 고차원 데이터를 저차원의 데이터로 변환하는 비지도 학습\n",
    "- 주성분 분석(Principal Component Analysis, PCA)\n",
    "   \n",
    "   \n",
    "## 3.3 강화학습\n",
    "- 학습하는 시스템이 행동을 실행하고 그 결과에 따른 보상이나 벌점을 받는 방식으로 학습. 학습이 계속되면서 가장 큰 보상을 얻기 위한 최상의 전략을 스스로 학습하게 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Scikit-learn\n",
    "- [사이킷런(scikit-learn)](https://scikit-learn.org/stable)\n",
    "- 파이썬 머신러닝 라이브러리가 가장 많이 사용된다. 딥러닝을 제외한 대부분의 머신러닝 알고리즘을 제공한다.\n",
    "- 파이썬 기반 다른 머신러닝 라이브러리가 사이킷런 스타일의 API를 지향할 정도로 쉽고 가장 파이썬스런 API를 제공한다. \n",
    "- 머신러닝 관련 다양한 알고리즘을 제공하며 모든 알고리즘에 일관성있는 사용법을 제공한다.\n",
    "\n",
    "\n",
    "## 4.1 설치\n",
    "- `conda install scikit-learn`\n",
    "- `pip install scikit-learn`\n",
    "\n",
    "\n",
    "## 4.2 Esimator와 transformer \n",
    "1.  Estimator (추정기)\n",
    "    - 데이터를 **학습**하고 **예측**하는 알고리즘(모델)들을 구현한 클래스들\n",
    "    - fit() : 데이터를 **학습**하는 메소드\n",
    "    - predict() : **예측**을 하는 메소드\n",
    "\n",
    "\n",
    "2. Transformer (변환기)\n",
    "    - 데이터 **전처리**를 하는 클래스들. 데이터 셋의 값의 형태를 변환한다.\n",
    "    - fit() : 어떻게 **변환**할지 학습하는 메소드\n",
    "    - transform() : **변환**처리 하는 메소드\n",
    "    - fit_transform() : fit()과 transform()을 같이 처리하는 메소드\n",
    "\n",
    "\n",
    "## 4.3 개발패턴 \n",
    "1. 데이터분리\n",
    "    - 데이터셋 모델을 학습시키기 위한 훈련 데이터 셋과 모델의 성능을 테스트 하기위한 테스트 데이터 셋으로 분리한다. \n",
    "1. 모델생성\n",
    "    - 예측 목적에 맞는 모델을 생성한다\n",
    "    - 하이퍼 파라미터 설정한다. 여기서 하이퍼 파라미터란 학습에 의해 찾는 값이 아닌 개발자가 직접 설정해야하는 파라미터를 의미한다. \n",
    "1. 모델학습 \n",
    "    - 훈련데이터로 모델 학습 \n",
    "1. 예측 \n",
    "    - predict / predict_prob (예측),  transform (변환)\n",
    "    - 테스트 데이터셋 예측 또는 변환\n",
    "1. 평가 \n",
    "    - 모델 성능을 평가한다.\n",
    "    - 정확도, AUC, R2, MSE 등 목적에 맞게 적절한 평가 함수를 이용해 결과를 확인한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 주요모듈 : TODO\n",
    "\n",
    "    \n",
    "    \n",
    "|분류|모듈명|내용|\n",
    "|--|--|--|\n",
    "|예제데이터 셋|sklearn.datasets|--|\n",
    "|feature 전처리|sklearn.preprocessing|--|\n",
    "||sklearn.feature_selection|--|\n",
    "||sklearn.feature_extraction|--|\n",
    "|데이터셋 분할|sklearn.model_selection|--|\n",
    "|모델 평가|sklearn.metrics|--|\n",
    "|머신러닝 알고리즘|sklearn.linear_model|--|\n",
    "||sklearn.ensemble|--|\n",
    "||sklearn.svm|--|\n",
    "||sklearn.neighbors|--|\n",
    "||sklearn.tree|--|\n",
    "||sklearn.cluster|--|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==== 02_첫번째 머신러닝 분석 - Iris_분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 분석실습 - Iris\n",
    "## 5.1 Iris 붗꽃 예측모델 \n",
    "소개정도 ### todo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 데이터셋 확인 \n",
    "### 5.2.1 용어 \n",
    "1. 레이블(Label), 타겟(Target)\n",
    "    - 결정값, 출력데이터, 종속변수\n",
    "    - 예측 대상이 되는 값. 지도학습시 **학습을 위해** 주어지는 정답 데이터\n",
    "    - 분류의 경우 레이블을 구성하는 고유값들을 **클래스(class)**라고 한다.\n",
    "\n",
    "\n",
    "2. 피쳐(Feature)\n",
    "    - 속성, 입력데이터, 독립변수\n",
    "    - Target이 왜 그런 값을 가지게 되었는지를 설명하는 변수. \n",
    "    - Target값을 **예측하기 위해** 학습해야 하는 값들. \n",
    "    \n",
    "### 5.2.2 데이터셋 가져오기 \n",
    "- scikit-learn은 머신러닝 모델을 테스트 하기위한 데이터셋을 제공한다.\n",
    "- 이런 데이터셋을 Toy dataset이라고 한다.\n",
    "- 패키지 : sklearn.datasets\n",
    "- 함수   : load_xxxx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': '/opt/anaconda3/lib/python3.8/site-packages/sklearn/datasets/data/iris.csv'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris() # 함수 임포트 호출하기 \n",
    "# iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.3 내장 데이터셋 구성 \n",
    "- scikit-learn의 dataset은 딕셔너리 형태의 Bunch 클래스 객체이다.\n",
    "- keys() 함수로 key값들을 조회\n",
    "   \n",
    "|구성|설명|\n",
    "|--|--|\n",
    "|**target_names**|예측하려는 값(class)을 가진 문자열 배열|\n",
    "|**target**|Label(출력데이터)|\n",
    "|**data**|Feature(입력변수)|\n",
    "|**feature_names**|입력변수 각 항목의 이름|\n",
    "|DESCR|데이터셋에 대한 설명|\n",
    "|filename|파일 경로 및 이름|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(iris['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris['DESCR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/anaconda3/lib/python3.8/site-packages/sklearn/datasets/data/iris.csv'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris['filename']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.4 데이터셋을 데이터프레임으로 \n",
    "- 데이터셋을 데이터 프레임 생성한 후 데이터를 확인한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   sepal length (cm)  150 non-null    float64\n",
      " 1   sepal width (cm)   150 non-null    float64\n",
      " 2   petal length (cm)  150 non-null    float64\n",
      " 3   petal width (cm)   150 non-null    float64\n",
      " 4   species            150 non-null    int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 6.0 KB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "iris_df = pd.DataFrame(iris['data'], columns = iris['feature_names'])\n",
    "iris_df['species'] = iris['target']\n",
    "iris_df\n",
    "iris_df.shape\n",
    "iris_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 예측 --> 결정트리모델을 이용해서 분류해보자! \n",
    "1. 문제정의 \n",
    "    - 내가 발견한 Iris 꽃받침(Sepal)의 길이(length)와 폭(width)이 각각 5cm, 3.5cm이고 꽃의 꽃잎(Petal)의 길이와 폭은 각각 1.4cm, 0.25cm이 이었다. 이 꽃는 Iris의 무슨 종일까?\n",
    "\n",
    "\n",
    "2. 데이터셋에서 찾아보기 \n",
    "    - 꽃받침(Sepal)의 길이(length)와 폭(width)이 각각 5cm, 3.5cm이고 꽃의 꽃잎(Petal)의 길이와 폭은 각각 1.4cm, 0.25cm이 이었다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'setosa'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df[(iris_df['sepal length (cm)'] == 5) & \n",
    "        (iris_df['sepal width (cm)'] == 3.5)]\n",
    "\n",
    "iris['target_names'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 머신러닝으로 우리가 하려는 것 \n",
    "    - 프로그래머가 직접 규칙(패턴)을 만드는 대신 컴퓨터가 데이터를 학습하여 규칙을 자동으로 만들도록 하는 것이다.\n",
    "    - 그렇다면 어떤 알고리즘을 통해서 구현할 수 있을까? \n",
    "\n",
    "### 5.3.1 결정트리 모델을 통해 분류하기\n",
    "- 독립 변수의 조건에 따라 종속 변수를 분리 \n",
    "- 머신러닝의 몇안되는 White box 모델\n",
    "- 결과에 대한 해석이 가능하다.\n",
    "- 과적합(Overfitting)이 잘 일어나는 단점이 있다. \n",
    "- 랜덤 포레스트(Random Forest), Gradient Boosting, Adaptive boosting과 같은 Boosting 계열 앙상블이 결정트리를  기반으로 하고 있다\n",
    "\n",
    "\n",
    "### 5.3.2 결정트리 모델 구현하기\n",
    "1. 모델 import\n",
    "2. 모델 생성\n",
    "3. 모델 학습시키기\n",
    "4. 예측 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['setosa'], dtype='<U10')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 모델 import\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 2. 모델생성 \n",
    "tree = DecisionTreeClassifier(random_state = 1) # 랜덤 값을 동일하게 하려면 \n",
    "\n",
    "# 3. 모델학습 \n",
    "# iris 데이터를 잘 분류할수 있도록 맞춰줘야한다. 내 데이터셋에 맞도록 피팅시켜야 한다. 트레이닝 \n",
    "# 학습 메서드 : fit, 학습 매개변수 : input_data(feature), output_data(label)\n",
    "# 2개의 값을 가지고 트리 모델에피팅시킨다. \n",
    "tree.fit(iris['data'], iris['target']) # DecisionTreeClassifier() 반환 \n",
    "\n",
    "# 4. 예측하기 \n",
    "# 꽃받침(Sepal)의 길이(length)와 폭(width)이 각각 5cm, 3.5cm이고 꽃의 꽃잎(Petal)의 길이와 폭은 각각 1.4cm, 0.25cm이 이었다.  \n",
    "\n",
    "# 예측메서드. 예측할 대상을 전달. 전달값을 feature을 준다. 2차원 배열로 넣어줘야한다. \n",
    "pred = tree.predict([[5, 3.5, 1.4, 0.25]])\n",
    "\n",
    "# 반환값이 레이블(label)이 된다.  array([0]) \n",
    "print(pred) \n",
    "\n",
    "# [0]번꽃이다. 그럼 [0]번 꽃이 뭐냐를 알아야겠지. \n",
    "iris['target_names'][pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'setosa', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 꽃을 여러개 예측해보자 \n",
    "my_irsis = [\n",
    "    [5, 3.5, 1.4, 0.25],\n",
    "    [5.1, 3.5, 1.4,0.2], \n",
    "    [2, 3, 5, 7]\n",
    "]\n",
    "\n",
    "pred2 = tree.predict(my_irsis) \n",
    "print(pred2) # 결과가 강사님과 다른데 그래도 되는지? ?? 랜덤하게 하기 때문에 다른게 결과가 나올 수 있음. \n",
    "\n",
    "iris['target_names'][pred2] # 이렇게 이름을 조회하면 되징. n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 분리\n",
    "- 위의 예는 우리가 만든 모델이 성능이 좋은 모델인지 나쁜 모델인지 알 수 없다.\n",
    "- 전체 데이터 셋을 두개의 데이터셋으로 나눠 하나(train_set)는 모델을 훈련할 때 사용하고 다른 하나(test_set)는 그 모델을 평가할 때 사용한다.\n",
    "- 보통 훈련데이터와 테스트데이터의 비율은 8:2 또는 7:3 정도로 나누는데 데이터셋이 충분하다면 6:4까지도 나눈다.\n",
    "- 데이터 셋을 분할 시 주의할 점은 각 클래스(분류대상)가 같은 비율로 나눠져야하는 점이다. \n",
    "\n",
    "### 5.4.1 train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # dataSet을 train Dataset, test datase으로 분할 \n",
    "iris['data']\n",
    "iris['target']\n",
    "\n",
    "# 8 : 2 로 트레인, 테스트 로 나눠서 해보자 \n",
    "# 매개변수로 인풋, output(target) 데이터를 넣으면 된다. \n",
    "X_train, X_test, y_train, y_test = train_test_split(iris['data'],  # input dataset\n",
    "                                 iris['target'], # output datase\n",
    "                                 test_size = 0.2, # test set의 비율 (0 - 1), default값은 2.5 이다. \n",
    "                                 stratify = iris['target'] # 클래스가 원본(raw data)과 같은 비율로 나눠라.                                                    \n",
    ") # 튜플로 반환된다.  X 는 인풋데이터 , Y는 아웃풋 데이터 \n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "\n",
    "y_test # 값들이 섞여서 나온다. ?? 무슨 의미지??? \n",
    "\n",
    "np.unique(y_test, return_counts = True) # 10, 10, 10 개로 동일하게 나왔다. # 1:1:1 비율로 같은 비율로 테스트도 나오게 된거다. \n",
    "\n",
    "np.unique(iris['target'], return_counts = True) # 원본을 보게 되면 50:50:50 왜? 위에 테스트셋 설정할때 staratify를 설정했기때문에 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.? 모델생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 모델학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.fit(X_train, y_train) # 트레인 값만 가지고 학습을 시켜본다 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 평가\n",
    "- 머신러닝 평가지표 함수들은 sklearn.metrics 모듈에 있다.\n",
    "\n",
    "### 5.6.1 accuracy_score(정확도) \n",
    "- 전체 데이터셋 중에 맞춘 갯수의 비율 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = tree.predict(X_train) # 2차열 배열로 만들어 준다. X_train이 2차월 배열로 구성되어 있다. \n",
    "pred_train\n",
    "\n",
    "from sklearn.metrics import accuracy_score # 정확도를 검증하는 함수 \n",
    "acc_train_score = accuracy_score(y_train, pred_train) # \n",
    "# 첫번째 매개변수에 정답을, 두번째 매개변수에 예측결과를\n",
    "\n",
    "print(\"train set 정확도 결과 :\", acc_train_score) # 1.0이면 정확도 120개 중에 120개가 다 맞음 \n",
    "\n",
    "# 진짜 테스트 셋으로도 확인해보자 \n",
    "pred_test = tree.predict(X_test)\n",
    "pred_test\n",
    "\n",
    "acc_train_score = accuracy_score(y_test,pred_test)\n",
    "acc_train_score # 30개 중에 29개가 맞은거 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6.2 confusion_matrix(혼동행렬)\n",
    "- 예측 한 것이 실제 무엇이었는지를 표로 구성한 평가 지표\n",
    "- 분류의 평가 지표로 사용된다.\n",
    "- axis=0: 실제, axis=1: 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm_train = confusion_matrix(y_train, pred_train)\n",
    "cm_test = confusion_matrix(y_test, pred_test)\n",
    "\n",
    "cm_train \n",
    "cm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==== 03_데이터셋 나누기와 교차검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ?. 데이터셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
